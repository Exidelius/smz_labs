{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    Optional,\n",
    "    Tuple,\n",
    "    Union,\n",
    ")\n",
    "\n",
    "import ipytest\n",
    "import numpy as np\n",
    "import pytest\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.common_types import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution2D(\n",
    "    input: Tensor,\n",
    "    weights: Tensor,\n",
    "    bias: Optional[Tensor] = None,\n",
    "    stride: Optional[Union[int, Tuple]] = 1,\n",
    "    padding: Optional[Union[int, Union[Tuple, str]]] = 0,\n",
    "    dilation: Optional[Union[int, Tuple]] = 1,\n",
    "    groups: Optional[int] = 1,\n",
    ") -> Tensor:\n",
    "    batch_size, in_channels, input_height, input_width = input.shape\n",
    "    out_channels, in_channels_groups, weights_height, weights_width = weights.shape\n",
    "\n",
    "    input = nn.functional.pad(input, (padding, padding, padding, padding))\n",
    "\n",
    "    result_height = (\n",
    "        input_height + 2 * padding - dilation * (weights_height - 1) - 1\n",
    "    ) // stride + 1\n",
    "    result_width = (\n",
    "        input_width + 2 * padding - dilation * (weights_width - 1) - 1\n",
    "    ) // stride + 1\n",
    "\n",
    "    grouped_channels = out_channels // groups if groups else out_channels\n",
    "\n",
    "    result = torch.zeros((batch_size, grouped_channels, result_height, result_width))\n",
    "\n",
    "    for batch in range(0, batch_size):\n",
    "        for channel in range(out_channels):\n",
    "            for i in range(0, input.shape[2] - (weights_height - 1), stride):\n",
    "                for j in range(0, input.shape[3] - (weights_width - 1), stride):\n",
    "                    for group in range(grouped_channels):\n",
    "                        result[:, group, i // stride, j // stride] = (\n",
    "                            weights[batch] * input[\n",
    "                                batch, :, i : i + weights_height, j : j + weights_width\n",
    "                            ]\n",
    "                        ).sum()\n",
    "            result[batch] += bias[channel] if bias else 0\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.fixture(scope='class')\n",
    "def inputs():\n",
    "    return torch.randn(1, 2, 4, 4)\n",
    "\n",
    "@pytest.fixture(scope='class')\n",
    "def weights():\n",
    "    return torch.randn(1, 2, 3, 3)\n",
    "\n",
    "@pytest.fixture(scope='class')\n",
    "def bias():\n",
    "    return torch.randn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.03s\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%ipytest -s\n",
    "\n",
    "@pytest.mark.usefixtures('inputs')\n",
    "@pytest.mark.usefixtures('weights')\n",
    "@pytest.mark.usefixtures('bias')\n",
    "class TestConv2D:\n",
    "    def test_conv2d_success(self, inputs, weights):\n",
    "        result = convolution2D(inputs, weights)\n",
    "        expected_result = nn.functional.conv2d(inputs, weights)\n",
    "        assert torch.allclose(expected_result, result)\n",
    "        \n",
    "    def test_conv2d_bias_success(self, inputs, weights, bias):\n",
    "        result = convolution2D(inputs, weights, bias)\n",
    "        expected_result = nn.functional.conv2d(inputs, weights, bias)\n",
    "        assert torch.allclose(expected_result, result)\n",
    "        \n",
    "    def test_conv2d_bias_padding_success(self, inputs, weights, bias):\n",
    "        result = convolution2D(inputs, weights, bias, padding=5)\n",
    "        expected_result = nn.functional.conv2d(inputs, weights, bias, padding=5)\n",
    "        assert torch.allclose(expected_result, result)\n",
    "        \n",
    "    def test_conv2d_bias_padding_stride_success(self, inputs, weights, bias):\n",
    "        result = convolution2D(inputs, weights, bias, padding=5, stride=2)\n",
    "        expected_result = nn.functional.conv2d(inputs, weights, bias, padding=5, stride=2)\n",
    "        assert torch.allclose(expected_result, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
